{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d338983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochasticdp import StochasticDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92014990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stages\n",
    "number_of_stages = 4\n",
    "# List of states\n",
    "states = [0, 5000, 10000]\n",
    "# List of decisions\n",
    "decisions = ['A', 'B', 'no investment']\n",
    "# Initialize stochastic dynamic program - we want to maximize, so minimize = False\n",
    "dp = StochasticDP(number_of_stages, states, decisions, minimize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee2873f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:156: UserWarning: The transition from state 5000 to state 0 in stage 0 under decision A is already defined. You are overwriting this transition data\n",
      "  warn(\"The transition from state {0} to state {1} in stage {2} \"\n",
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:156: UserWarning: The transition from state 5000 to state 10000 in stage 0 under decision B is already defined. You are overwriting this transition data\n",
      "  warn(\"The transition from state {0} to state {1} in stage {2} \"\n",
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:156: UserWarning: The transition from state 5000 to state 10000 in stage 1 under decision A is already defined. You are overwriting this transition data\n",
      "  warn(\"The transition from state {0} to state {1} in stage {2} \"\n",
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:156: UserWarning: The transition from state 5000 to state 0 in stage 1 under decision A is already defined. You are overwriting this transition data\n",
      "  warn(\"The transition from state {0} to state {1} in stage {2} \"\n",
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:156: UserWarning: The transition from state 5000 to state 10000 in stage 1 under decision B is already defined. You are overwriting this transition data\n",
      "  warn(\"The transition from state {0} to state {1} in stage {2} \"\n",
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:156: UserWarning: The transition from state 5000 to state 10000 in stage 2 under decision A is already defined. You are overwriting this transition data\n",
      "  warn(\"The transition from state {0} to state {1} in stage {2} \"\n",
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:156: UserWarning: The transition from state 5000 to state 0 in stage 2 under decision A is already defined. You are overwriting this transition data\n",
      "  warn(\"The transition from state {0} to state {1} in stage {2} \"\n",
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:156: UserWarning: The transition from state 5000 to state 10000 in stage 2 under decision B is already defined. You are overwriting this transition data\n",
      "  warn(\"The transition from state {0} to state {1} in stage {2} \"\n"
     ]
    }
   ],
   "source": [
    "# Transition probabilities and contributions from state n = 5000\n",
    "for t in range(number_of_stages - 1):\n",
    "    # Investment A\n",
    "    #dp.add_transition[10000, 5000, t, 'A'] = 0.7\n",
    "    dp.add_transition(stage=t, from_state=5000, decision='A', to_state=10000, probability=0.7, contribution=0)\n",
    "    dp.contribution[10000, 5000, t, 'A'] = 0\n",
    "    #dp.transition[0, 5000, t, 'A'] = 0.3\n",
    "    dp.add_transition(stage=t, from_state=5000, decision='A', to_state=0, probability=0.3, contribution=0)\n",
    "    dp.contribution[0, 5000, t, 'A'] = 0\n",
    "    # Investment B\n",
    "    #dp.transition[10000, 5000, t, 'B'] = 0.1\n",
    "    dp.add_transition(stage=t, from_state=5000, decision=\"B\", to_state=10000, probability=0.1, contribution=0)\n",
    "    dp.contribution[10000, 5000, t, 'B'] = 0\n",
    "    #dp.transition[5000, 5000, t, 'B'] = 0.9\n",
    "    dp.add_transition(stage=t, from_state=5000, decision=\"A\", to_state=5000, probability=0.9, contribution=0)\n",
    "    dp.contribution[5000, 5000, t, 'B'] = 0\n",
    "    # No investment\n",
    "    #dp.transition[5000, 5000, t, 'no investment'] = 1\n",
    "    dp.add_transition(stage=t, from_state=5000, decision=\"A\", to_state=5000, probability=1, contribution=0)\n",
    "    dp.contribution[5000, 5000, t, 'no investment'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef1014e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Invalid state, stage, or decision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_stages \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Investment A - all transitions have probability 0, already done in initialization\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Investment B - all transitions have probability 0, already done in initialization\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# No investment\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#dp.transition[0, 0, t, 'no investment'] = 1\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_transition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mno investment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     dp\u001b[38;5;241m.\u001b[39mcontribution[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno investment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:154\u001b[0m, in \u001b[0;36mStochasticDP.add_transition\u001b[1;34m(self, stage, from_state, decision, to_state, probability, contribution)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_transition\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage, from_state, decision, to_state,\n\u001b[0;32m    153\u001b[0m                    probability, contribution):\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m[\u001b[49m\u001b[43mto_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    155\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontribution[to_state, from_state, stage, decision]):\n\u001b[0;32m    156\u001b[0m         warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe transition from state \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m to state \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m in stage \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder decision \u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m is already defined. You are overwriting \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis transition data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m              \u001b[38;5;241m.\u001b[39mformat(from_state, to_state, stage, decision))\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability[to_state, from_state, stage, decision] \u001b[38;5;241m=\u001b[39m probability\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:40\u001b[0m, in \u001b[0;36mTransitionData.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         (n \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         (t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_stages)) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         (x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecisions)):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid state, stage, or decision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Invalid state, stage, or decision'"
     ]
    }
   ],
   "source": [
    "for t in range(number_of_stages - 1):\n",
    "# Investment A - all transitions have probability 0, already done in initialization\n",
    "# Investment B - all transitions have probability 0, already done in initialization\n",
    "# No investment\n",
    "    #dp.transition[0, 0, t, 'no investment'] = 1\n",
    "    dp.add_transition(stage=t, from_state=0, decision=\"'no investment'\", to_state=0, probability=1, contribution=0)\n",
    "    dp.contribution[0, 0, t, 'no investment'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f654458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KENNEDY\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:166: UserWarning: The boundary condition at state 10000 is already defined. You are overwriting this boundary condition\n",
      "  warn(\"The boundary condition at state {0} is already defined. \"\n"
     ]
    }
   ],
   "source": [
    "dp.add_boundary(state=0, value=0)\n",
    "dp.add_boundary(state=5000, value=0)\n",
    "dp.add_boundary(state=10000, value=1)\n",
    "# dp.boundary[0] = 0\n",
    "# dp.boundary[5000] = 0\n",
    "# dp.boundary[10000] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e6f047d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dynamic program is not well-defined. Check the transition probabilities from state 5000 at stage 0 under decision A",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m value, policy \u001b[38;5;241m=\u001b[39m \u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stochasticdp\\stochasticdp.py:192\u001b[0m, in \u001b[0;36mStochasticDP.solve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    191\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    193\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDynamic program is not well-defined. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck the transition probabilities \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom state \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m at stage \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m under decision \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(n, t, x)\n\u001b[0;32m    197\u001b[0m                 )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Value function\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# value[t, n]\u001b[39;00m\n\u001b[0;32m    201\u001b[0m value \u001b[38;5;241m=\u001b[39m StageStateData(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_stages, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates)\n",
      "\u001b[1;31mValueError\u001b[0m: Dynamic program is not well-defined. Check the transition probabilities from state 5000 at stage 0 under decision A"
     ]
    }
   ],
   "source": [
    "value, policy = dp.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b8d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.add_transition(stage=0, from_state=5000, decision=A, to_state=10000, probability=0.7, contribution=0)\n",
    "\n",
    "# This sets dp.boundary[n] = v\n",
    "dp.boundary(state=n, value=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24cbe9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(stage: 0, state: 0): 30\n",
      " (stage: 0, state: 1): 23\n",
      " (stage: 0, state: 2): 22\n",
      " (stage: 0, state: 3): 21\n",
      " (stage: 1, state: 0): 23\n",
      " (stage: 1, state: 1): 21\n",
      " (stage: 1, state: 2): 19\n",
      " (stage: 1, state: 3): 12\n",
      " (stage: 2, state: 0): inf\n",
      " (stage: 2, state: 1): 11\n",
      " (stage: 2, state: 2): 9\n",
      " (stage: 2, state: 3): 7\n",
      " (stage: 3, state: 0): 0\n",
      " (stage: 3, state: 1): 0\n",
      " (stage: 3, state: 2): 0\n",
      " (stage: 3, state: 3): 0}\n",
      "{(stage: 0, state: 0): {1}\n",
      " (stage: 0, state: 1): {0}\n",
      " (stage: 0, state: 2): {0}\n",
      " (stage: 0, state: 3): {0}\n",
      " (stage: 1, state: 0): {3}\n",
      " (stage: 1, state: 1): {2}\n",
      " (stage: 1, state: 2): {1}\n",
      " (stage: 1, state: 3): {0}\n",
      " (stage: 2, state: 0): None\n",
      " (stage: 2, state: 1): {3}\n",
      " (stage: 2, state: 2): {2}\n",
      " (stage: 2, state: 3): {1}}\n"
     ]
    }
   ],
   "source": [
    "# Adaptation of Exercise 9-26 from\n",
    "#\n",
    "# R. Rardin (1998). Optimization in operations research. Prentice Hall.\n",
    "#\n",
    "# The Dijkstra Brewing Company is planning production of its new limited run\n",
    "# beer, Primal Pilsner. The company must supply 1 batch next month, then 2 and\n",
    "# 4 in successive months. Each month in which the company produces the beer\n",
    "# requires a factory setup cost of \\$5,000. Each batch of beer costs \\$2,000 to\n",
    "# produce. Batches can be held in inventory at a cost of \\$1,000 per batch per\n",
    "# month. Capacity limitations allow a maximum of 3 batches to be produced\n",
    "# during each month. In addition, the size of the company's warehouse restricts\n",
    "# the ending inventory for each month to at most 3 batches. The company has no\n",
    "# initial inventory.\n",
    "#\n",
    "# The company wants to find a production plan that will meet all demands on time\n",
    "# and minimizes its total production and holding costs over the next 3 months.\n",
    "# Formulate this problem as a dynamic program.\n",
    "\n",
    "#from stochasticdp import StochasticDP\n",
    "\n",
    "d = [1, 2, 4]\n",
    "\n",
    "number_of_stages = 4\n",
    "states = [0, 1, 2, 3]\n",
    "#states = [0, 5000, 10000]\n",
    "decisions = [0, 1, 2, 3]\n",
    "#decisions = ['A', 'B', 'no investment']\n",
    "dp = StochasticDP(number_of_stages, states, decisions, minimize=True)\n",
    "\n",
    "for t in range(number_of_stages - 1):\n",
    "    for n in states:\n",
    "        for x in decisions:\n",
    "            if n + x - d[t] <= 3 and n + x - d[t] >= 0:\n",
    "                c = 5 * (x > 0) + 2 * x + 1 * (n + x - d[t])\n",
    "                dp.add_transition(stage=t,\n",
    "                                  from_state=n,\n",
    "                                  decision=x,\n",
    "                                  to_state=n + x - d[t],\n",
    "                                  probability=1,\n",
    "                                  contribution=c)\n",
    "\n",
    "for n in states:\n",
    "    dp.add_boundary(state=n, value=0)\n",
    "\n",
    "value, policy = dp.solve()\n",
    "\n",
    "print(value)\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f44ae01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(stage: 0, state: 0): 0\n",
      " (stage: 0, state: 1): 675.0\n",
      " (stage: 1, state: 0): 0\n",
      " (stage: 1, state: 1): 700.0\n",
      " (stage: 2, state: 0): 0\n",
      " (stage: 2, state: 1): 800.0\n",
      " (stage: 3, state: 0): 0\n",
      " (stage: 3, state: 1): 1600}\n",
      "{(stage: 0, state: 0): {0}\n",
      " (stage: 0, state: 1): {2}\n",
      " (stage: 1, state: 0): {0}\n",
      " (stage: 1, state: 1): {2, 3}\n",
      " (stage: 2, state: 0): {0}\n",
      " (stage: 2, state: 1): {3, 4}}\n"
     ]
    }
   ],
   "source": [
    "# Adaptation of Example 11.6 from\n",
    "#\n",
    "# F. S. Hillier and G. J. Lieberman (1990). Introduction to operations\n",
    "# research. McGraw-Hill.\n",
    "#\n",
    "# The Hit-and-Miss Manufacturing Company has received an order to supply one\n",
    "# item of a particular type. However, manufacturing this item is difficult, and\n",
    "# the customer has specified such stringent quality requirements that the\n",
    "# company may have to produce more than one item to obtain an item that is\n",
    "# acceptable.\n",
    "#\n",
    "# The company estimates that each item of this type will be acceptable with\n",
    "# probability $1/2$ and defective with probability $1/2$. Each item costs \\$100\n",
    "# to produce, and excess items are worthless. In addition, a setup cost of\n",
    "# \\$300 must be incurred whenever the production process is setup for this\n",
    "# item. The company has time to make no more than 3 production runs, and at\n",
    "# most 5 items can be produced in each run. If an acceptable item has not been\n",
    "# obtained by the end of the third production run, the manufacturer is in\n",
    "# breach of contract and must pay a penalty of \\$1600.\n",
    "\n",
    "# The objective is to determine how many items to produce in each production run\n",
    "# in order to minimize the total expected cost.\n",
    "\n",
    "from stochasticdp import StochasticDP\n",
    "\n",
    "number_of_stages = 4\n",
    "states = [0, 1]\n",
    "decisions = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "dp = StochasticDP(number_of_stages, states, decisions, minimize=True)\n",
    "\n",
    "for t in range(number_of_stages - 1):\n",
    "    # From state 0\n",
    "    for x in decisions:\n",
    "        dp.add_transition(stage=t, from_state=0, decision=x, to_state=0,\n",
    "                          probability=1, contribution=300 * (x > 0) + 100 * x)\n",
    "        dp.add_transition(stage=t, from_state=0, decision=x, to_state=1,\n",
    "                          probability=0, contribution=300 * (x > 0) + 100 * x)\n",
    "\n",
    "    # From state 1\n",
    "    for x in decisions:\n",
    "        dp.add_transition(stage=t, from_state=1, decision=x, to_state=0,\n",
    "                          probability=1 - (1/2) ** x,\n",
    "                          contribution=300 * (x > 0) + 100 * x)\n",
    "        dp.add_transition(stage=t, from_state=1, decision=x, to_state=1,\n",
    "                          probability=(1/2) ** x,\n",
    "                          contribution=300 * (x > 0) + 100 * x)\n",
    "\n",
    "dp.add_boundary(state=0, value=0)\n",
    "dp.add_boundary(state=1, value=1600)\n",
    "\n",
    "value, policy = dp.solve()\n",
    "\n",
    "print(value)\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499b5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
